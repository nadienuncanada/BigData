# ğŸ“Œ Trabajos PrÃ¡cticos - Conceptos y Aplicaciones Big Data

Este repositorio contiene trabajos prÃ¡cticos y ejercicios de la materia **Conceptos y Aplicaciones Big Data**, donde se han utilizado diversas herramientas del ecosistema Big Data para el procesamiento y anÃ¡lisis de grandes volÃºmenes de datos. ğŸš€

## ğŸ› ï¸ TecnologÃ­as y Herramientas Utilizadas
- âš¡ **Apache Spark**: Procesamiento distribuido de datos en memoria.
- ğŸ”„ **Spark Streaming**: Procesamiento en tiempo real de flujos de datos.
- ğŸ“‚ **Hadoop MapReduce**: Modelo de programaciÃ³n para procesamiento distribuido en grandes datasets.
- ğŸ **Python**: Lenguaje de programaciÃ³n utilizado para desarrollar los ejercicios.
- â˜ï¸ **Google Colab**: Entorno de ejecuciÃ³n en la nube que permite utilizar Spark y Hadoop sin necesidad de configuraciones locales complejas.

## ğŸ“ Contenido
Cada carpeta del repositorio contiene trabajos prÃ¡cticos y ejercicios con su respectiva explicaciÃ³n y cÃ³digo fuente:

1. ğŸ“Œ **[01-Spark]**: IntroducciÃ³n a Apache Spark y manipulaciÃ³n de RDDs y DataFrames.
2. ğŸ”„ **[02-Spark-Streaming]**: Procesamiento de flujos de datos en tiempo real con Spark Streaming.
3. ğŸ“‚ **[03-Hadoop-MapReduce]**: ImplementaciÃ³n de MapReduce en Python para procesamiento distribuido.

## âš™ï¸ Requisitos
Para ejecutar los ejercicios en Google Colab, se deben seguir los siguientes pasos:

1. ğŸ”— **Montar Google Drive** (si es necesario para almacenamiento de datos).
2. ğŸ› ï¸ **Instalar y configurar Apache Spark y Hadoop en Google Colab** solo con ejecutar la celda Inicializacion y dando los permisos necesarios ya funcionaria con los datasets que la catedra nos dio.


## ğŸ‘¥ Autores
Este proyecto fue desarrollado en el marco de la materia **Conceptos y Aplicaciones Big Data** por **Ignacio Nicolas Melo y Nicolas Ricciardi**.



---


